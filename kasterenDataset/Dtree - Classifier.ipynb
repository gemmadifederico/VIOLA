{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, _tree\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as pltimg\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the two datasets \n",
    "\n",
    "df = pd.read_csv(\"log_labeled_trans.csv\", header = 0).fillna(0)\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df['Label']=df['Label'].str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Start_time', 'End_time', 'Hall-Bedroom_door', 'Hall-Bathroom_door', 'ToiletFlush', 'Plates_cupboard', 'Fridge', 'Microwave', 'Groceries_Cupboard', 'Hall-Toilet_door', 'Frontdoor', 'Pans_Cupboard', 'Freezer', 'Cups_cupboard', 'Dishwasher', 'Washingmachine', 'Label', 'Label_ID', 'Activity_Size']\n"
     ]
    }
   ],
   "source": [
    "data_top = df.columns\n",
    "columns = list(data_top) \n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hall-Bedroom_door',\n",
       " 'Hall-Bathroom_door',\n",
       " 'ToiletFlush',\n",
       " 'Plates_cupboard',\n",
       " 'Fridge',\n",
       " 'Microwave',\n",
       " 'Groceries_Cupboard',\n",
       " 'Hall-Toilet_door',\n",
       " 'Frontdoor',\n",
       " 'Pans_Cupboard',\n",
       " 'Freezer',\n",
       " 'Cups_cupboard',\n",
       " 'Dishwasher',\n",
       " 'Washingmachine',\n",
       " 'Activity_Size']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = columns\n",
    "features.remove(\"Label\")\n",
    "features.remove(\"Label_ID\")\n",
    "features.remove(\"Start_time\")\n",
    "features.remove(\"End_time\")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "# y = df.Label_ID\n",
    "y = df.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rules_recursive(clf,features,node,expression,rules):\n",
    "    # intermediate node\n",
    "    if clf.tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "        name = features[clf.tree_.feature[node]]\n",
    "        threshold = clf.tree_.threshold[node]\n",
    "        if expression != '':\n",
    "            expression = expression + ' AND '\n",
    "        create_rules_recursive(clf,features,clf.tree_.children_left[node],expression + str(name) + '<=' + str(threshold),rules)\n",
    "        create_rules_recursive(clf,features,clf.tree_.children_right[node],expression + str(name) + '>' + str(threshold),rules)\n",
    "    # leaf node\n",
    "    else:\n",
    "        key = clf.classes_[np.argmax(clf.tree_.value[node])]\n",
    "        if (key not in rules):\n",
    "            rules[key] = '(' + expression + ')'\n",
    "        else:\n",
    "            rules[key] = rules[key] + ' OR (' + expression + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decision_rules(rf,features):\n",
    "\n",
    "    tree = rf.tree_\n",
    "    assert tree.value.shape[1] == 1 # no support for multi-output\n",
    "    \n",
    "    iterator = enumerate(zip(tree.children_left, tree.children_right, tree.feature, tree.threshold, tree.value))\n",
    "    for node_idx, data in iterator:\n",
    "        left, right, feature, th, value = data\n",
    "\n",
    "        # left: index of left child (if any)\n",
    "        # right: index of right child (if any)\n",
    "        # feature: index of the feature to check\n",
    "        # th: the threshold to compare against\n",
    "        # value: values associated with classes            \n",
    "\n",
    "        # for classifier, value is 0 except the index of the class to return\n",
    "        class_idx = np.argmax(value[0])\n",
    "\n",
    "        if left == -1 and right == -1:\n",
    "            print('{} LEAF: return class={}'.format(node_idx, class_idx))\n",
    "        else:\n",
    "            print('{} NODE: if {} < {} then next={} else next={}'.format(node_idx, features[feature], th, left, right))    \n",
    "            print('{} NODE: if {} < {} then next={} else next={}'.format(node_idx, feature, th, left, right))    \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'feature_names_in_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39m# Train Decision Tree Classifer\u001b[39;00m\n\u001b[0;32m      6\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(clf\u001b[39m.\u001b[39;49mfeature_names_in_)\n\u001b[0;32m      8\u001b[0m \u001b[39mprint\u001b[39m(clf\u001b[39m.\u001b[39mclasses_)\n\u001b[0;32m      9\u001b[0m \u001b[39m# print_decision_rules(clf,features)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'feature_names_in_'"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "# print(clf.feature_names_in_)\n",
    "print(clf.classes_)\n",
    "# print_decision_rules(clf,features)\n",
    "rules = dict()\n",
    "create_rules_recursive(clf,features,0,'',rules)\n",
    "print(rules)\n",
    "print(export_text(clf))\n",
    "\n",
    "dump(clf, 'test.joblib') \n",
    "\n",
    "data = tree.export_graphviz(clf, out_file=None, feature_names=features)\n",
    "graph = pydotplus.graph_from_dot_data(data)\n",
    "graph.write_png('mydecisiontree_classifier_test.png')\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# img=pltimg.imread('mydecisiontree.png')\n",
    "# imgplot = plt.imshow(img)\n",
    "# plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "        get_drink       0.50      0.50      0.50         2\n",
      "        go_to_bed       1.00      1.00      1.00         2\n",
      "      leave_house       1.00      0.88      0.93         8\n",
      "prepare_Breakfast       1.00      0.90      0.95        10\n",
      "      take_shower       0.75      1.00      0.86         6\n",
      "       use_toilet       1.00      1.00      1.00         7\n",
      "\n",
      "         accuracy                           0.91        35\n",
      "        macro avg       0.88      0.88      0.87        35\n",
      "     weighted avg       0.93      0.91      0.92        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to predict the take shower activity, with ID 5, \n",
      "with the following combination 1,0,0,0,0,0,0,3,0,0,0,0,0,0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 14 features, but DecisionTreeClassifier is expecting 15 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrying to predict the take shower activity, with ID 5, \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mwith the following combination 1,0,0,0,0,0,0,3,0,0,0,0,0,0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict([[\u001b[39m1\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m]])\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mValue predicted:\u001b[39m\u001b[39m\"\u001b[39m, pred)\n\u001b[0;32m      4\u001b[0m \u001b[39mif\u001b[39;00m(pred \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m): \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCorrect prediction\u001b[39m\u001b[39m\"\u001b[39m) \n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:505\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \n\u001b[0;32m    484\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    504\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[0;32m    506\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[0;32m    507\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:471\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 471\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    472\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    473\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[0;32m    474\u001b[0m     ):\n\u001b[0;32m    475\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 14 features, but DecisionTreeClassifier is expecting 15 features as input."
     ]
    }
   ],
   "source": [
    "print(\"Trying to predict the take shower activity, with ID 5, \\nwith the following combination 1,0,0,0,0,0,0,3,0,0,0,0,0,0\")\n",
    "pred = clf.predict([[1,0,0,0,0,0,0,3,0,0,0,0,0,0]])\n",
    "print(\"Value predicted:\", pred)\n",
    "if(pred == 5): print(\"Correct prediction\") \n",
    "else: print(\"Wrong predicition\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
